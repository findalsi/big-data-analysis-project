{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66fb3ee5",
   "metadata": {},
   "source": [
    "# üìò Final Project: Data Analysis using MongoDB and Apache Spark\n",
    "\n",
    "This project demonstrates how to work with a real-world dataset (Amazon Books Reviews Dataset) using MongoDB for storage and Apache Spark (PySpark) for processing. We explore schema design, querying, performance optimization, and visual insights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f56ae",
   "metadata": {},
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df144e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Configure Pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb67d72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Load CSV files\n",
    "books_df = pd.read_csv(\"books_data.csv\")\n",
    "ratings_df = pd.read_csv(\"Books_rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bd1d8",
   "metadata": {},
   "source": [
    "## üìÇ Dataset Overview\n",
    "\n",
    "We use the **Amazon Books Reviews** dataset from Kaggle, which contains user-generated reviews for a wide variety of books available on Amazon. This real-world dataset includes valuable attributes such as:\n",
    "\n",
    "- **Title**: The name of the book.\n",
    "- **Author(s)**: The author(s) of the book.\n",
    "- **Categories**: Genre or subject of the book (e.g., Comics, Fiction, Education).\n",
    "- **Rating**: User rating scores, typically from 1 to 5.\n",
    "- **Review Text**: Actual written review provided by users.\n",
    "- **Review Date**: When the review was posted.\n",
    "- **ASIN**: Unique Amazon product identifier for each book.\n",
    "\n",
    "This dataset provides an excellent foundation for exploring data storage, processing, and analysis using MongoDB and Apache Spark due to its unstructured nature and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0d1a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Basic exploration\n",
    "print(\"üìò Books Data Sample:\")\n",
    "print(books_df.head(), \"\\n\")\n",
    "\n",
    "print(\"üìù Ratings Data Sample:\")\n",
    "print(ratings_df.head(), \"\\n\")\n",
    "\n",
    "print(\"üìä Shapes:\")\n",
    "print(\"Books Data Shape:\", books_df.shape)\n",
    "print(\"Ratings Data Shape:\", ratings_df.shape, \"\\n\")\n",
    "\n",
    "print(\"üîç Missing Values in Books Data:\")\n",
    "print(books_df.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"üîç Missing Values in Ratings Data:\")\n",
    "print(ratings_df.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02a937",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Optional Cleaning\n",
    "# Drop rows with missing essential review text\n",
    "ratings_df = ratings_df.dropna(subset=[\"review/text\"])\n",
    "\n",
    "\n",
    "# Fill missing summaries with a placeholder (safe version)\n",
    "ratings_df[\"review/summary\"] = ratings_df[\"review/summary\"].fillna(\"No summary provided\")\n",
    "\n",
    "\n",
    "# You can apply similar cleaning to books_df if needed\n",
    "# books_df = books_df.dropna()  # example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa326a4e",
   "metadata": {},
   "source": [
    "## üóÉ Storing Dataset in MongoDB\n",
    "We connect to MongoDB and insert our dataset using an optimized¬†schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc2d55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Connect to MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")  # Change if hosted elsewhere\n",
    "db = client[\"books_database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e86966",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7: Convert DataFrames to list of dictionaries\n",
    "books_data = books_df.to_dict(\"records\")\n",
    "ratings_data = ratings_df.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d652ef84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pymongo.errors import BulkWriteError\n",
    "\n",
    "def insert_in_batches(collection, data, batch_size=100):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        batch = data[i:i+batch_size]\n",
    "        try:\n",
    "            collection.insert_many(batch)\n",
    "        except BulkWriteError as bwe:\n",
    "            print(f\"‚ùå Bulk write error: {bwe.details}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error inserting batch {i // batch_size}: {e}\")\n",
    "\n",
    "db[\"books\"].drop()\n",
    "db[\"ratings\"].drop()\n",
    "\n",
    "db[\"books\"].insert_many(books_data)\n",
    "insert_in_batches(db[\"ratings\"], ratings_data)\n",
    "\n",
    "print(\"‚úÖ Data inserted into MongoDB¬†successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a344e6",
   "metadata": {},
   "source": [
    "## ‚öô Data Processing with PySpark\n",
    "We use PySpark to read, transform, and analyze the dataset loaded from MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e1e2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BooksMiniProject\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Step 2: Load your CSV files into Spark DataFrames\n",
    "books_df = spark.read.csv(\"books_data.csv\", header=True, inferSchema=True)\n",
    "ratings_df = spark.read.csv(\"Books_rating.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Optional: Show first few rows for confirmation\n",
    "books_df.show(5)\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6de1d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Read documents from MongoDB, exclude '_id'\n",
    "books_docs = list(db[\"books\"].find({}, {\"_id\": 0}))\n",
    "ratings_docs = list(db[\"ratings\"].find({}, {\"_id\": 0}).limit(10000))  # üîÅ Adjust limit as needed\n",
    "\n",
    "# Convert to Spark DataFrames\n",
    "df_books = spark.createDataFrame(books_docs)\n",
    "df_ratings = spark.createDataFrame(ratings_docs)\n",
    "\n",
    "# Show sample rows\n",
    "df_books.show(3)\n",
    "df_ratings.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a5adc6",
   "metadata": {},
   "source": [
    "## üîç Querying with Spark SQL\n",
    "Analyze average ratings using Spark SQL and display top-rated books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560de860",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Optional: rename to avoid column name conflict during join\n",
    "df_ratings = df_ratings.withColumnRenamed(\"review/score\", \"rating_score\")\n",
    "\n",
    "# Perform inner join on Title\n",
    "df_joined = df_ratings.join(df_books, on=\"Title\", how=\"inner\")\n",
    "\n",
    "# Select relevant columns\n",
    "df_selected = df_joined.select(\n",
    "    \"Title\",\n",
    "    \"authors\",\n",
    "    \"categories\",\n",
    "    \"rating_score\"\n",
    ")\n",
    "\n",
    "# Compute average rating per book\n",
    "df_avg = df_selected.groupBy(\"Title\", \"authors\", \"categories\") \\\n",
    "    .agg(avg(\"rating_score\").alias(\"avg_rating\")) \\\n",
    "    .orderBy(\"avg_rating\", ascending=False)\n",
    "\n",
    "# Show top 10 rated books\n",
    "df_avg.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12250aab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get top 10 books from df_avg\n",
    "top_books = df_avg.limit(10).toPandas().to_dict(\"records\")\n",
    "\n",
    "# Save to MongoDB\n",
    "db[\"top_books\"].drop()  # Drop existing collection if it exists\n",
    "db[\"top_books\"].insert_many(top_books)  # Insert top books\n",
    "\n",
    "print(\"‚úÖ Top 10 books saved to MongoDB collection 'top_books'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965504ef",
   "metadata": {},
   "source": [
    "## üìä Genre-Based Filtering\n",
    "We filter and analyze specific genres like Comics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236f6b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Filter books where categories contain \"Comics\"\n",
    "df_comics = df_avg.filter(df_avg.categories.contains(\"Comics\"))\n",
    "df_comics.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d4841",
   "metadata": {},
   "source": [
    "### Indexing for Performance\n",
    "\n",
    "Create indexes on frequently used fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdddf47",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "db[\"books\"].create_index(\"Title\")\n",
    "db[\"books\"].create_index(\"publishedDate\")\n",
    "db[\"books\"].create_index(\"categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f64bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "list(db[\"books\"].list_indexes())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06fe030",
   "metadata": {},
   "source": [
    "## üìà Visualization of Top-Rated Books\n",
    "Using Matplotlib to show top-rated books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819a255",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to Pandas DataFrame from Spark DataFrame\n",
    "top_books_df = df_avg.limit(10).toPandas()\n",
    "\n",
    "# Check if the DataFrame is not empty and contains required columns\n",
    "if not top_books_df.empty and 'Title' in top_books_df.columns and 'avg_rating' in top_books_df.columns:\n",
    "    # Plot horizontal bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(top_books_df['Title'], top_books_df['avg_rating'], color='skyblue')\n",
    "    plt.xlabel(\"Average Rating\")\n",
    "    plt.title(\"Top 10 Rated Books\")\n",
    "    plt.gca().invert_yaxis()  # Puts highest-rated book at the top\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"‚ö† DataFrame is empty or missing required columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961f7e9d",
   "metadata": {},
   "source": [
    "## üìÜ Year-Based Analysis\n",
    "Analyzing books by year of¬†publication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0810082e",
   "metadata": {},
   "source": [
    "Filter by Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0270afb3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Join df_avg with df_books to access publishedDate\n",
    "df_avg_with_date = df_avg.join(df_books.select('Title', 'publishedDate'), on='Title', how='inner')\n",
    "\n",
    "# Filter books published after 2010\n",
    "df_recent_books = df_avg_with_date.filter(df_avg_with_date.publishedDate >= '2010')\n",
    "\n",
    "# Show result\n",
    "df_recent_books.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25713116",
   "metadata": {},
   "source": [
    "# Genre Distribution (Pie Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb57be3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get the count of books by genre\n",
    "genre_counts = df_avg.select(\"categories\").rdd.flatMap(lambda x: x).countByValue()\n",
    "\n",
    "# Sort by count and take top N\n",
    "top_n = 10\n",
    "sorted_genre_counts = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Separate top N genres and the \"Others\"\n",
    "top_genres = sorted_genre_counts[:top_n]\n",
    "other_genres = sorted_genre_counts[top_n:]\n",
    "\n",
    "# Combine remaining genres into \"Other\"\n",
    "if other_genres:\n",
    "    top_genres.append((\"Other\", sum([count for _, count in other_genres])))\n",
    "\n",
    "# Prepare data for plotting\n",
    "genre_labels = [str(k) for k, _ in top_genres]\n",
    "genre_sizes = [v for _, v in top_genres]\n",
    "\n",
    "# Plot pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(genre_sizes, labels=genre_labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)\n",
    "plt.title(\"Top Genres in Books (Others Combined)\")\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39e685",
   "metadata": {},
   "source": [
    "#  Books Published by Year (Bar Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32630c77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert Spark DataFrame to Pandas (limit to avoid memory overload)\n",
    "year_counts_df = df_books.select(\"publishedDate\").limit(100000).toPandas()\n",
    "\n",
    "# Extract the year from the publishedDate\n",
    "year_counts_df['Year'] = pd.to_datetime(year_counts_df['publishedDate'], errors='coerce').dt.year\n",
    "\n",
    "# Drop rows with NaN Year values\n",
    "year_counts_df = year_counts_df.dropna(subset=['Year'])\n",
    "\n",
    "# Create a new column for decade categorization\n",
    "year_counts_df['Decade'] = (year_counts_df['Year'] // 10) * 10\n",
    "\n",
    "# Group by Decade and count the number of books\n",
    "decade_counts = year_counts_df.groupby('Decade').size().reset_index(name='Book Count')\n",
    "\n",
    "# Sort the decades for the plot\n",
    "decade_counts = decade_counts.sort_values(by='Decade')\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(decade_counts['Decade'].astype(str), decade_counts['Book Count'], color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Decade\")\n",
    "plt.ylabel(\"Number of Books Published\")\n",
    "plt.title(\"Books Published by Decade\")\n",
    "plt.xticks(rotation=45)  # Rotate labels for better readability\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66de5d2",
   "metadata": {},
   "source": [
    "# Average Rating by Genre (Box Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb97452",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the Spark DataFrame to Pandas for Seaborn plotting\n",
    "df_genre_ratings = df_avg.select(\"categories\", \"avg_rating\").toPandas()\n",
    "\n",
    "# Group genres by frequency and get top 10\n",
    "top_genres = df_genre_ratings['categories'].value_counts().nlargest(10).index\n",
    "\n",
    "# Filter the dataframe to include only the top genres\n",
    "df_top_genres = df_genre_ratings[df_genre_ratings['categories'].isin(top_genres)]\n",
    "\n",
    "# Plot horizontal box plot with top genres\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x=\"avg_rating\", y=\"categories\", data=df_top_genres, palette=\"Set2\")\n",
    "plt.title(\"Rating Distribution by Top 10 Genres\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffee0e97",
   "metadata": {},
   "source": [
    "#  Rating Distribution (Histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e90b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert ratings to Pandas for plotting\n",
    "ratings = df_avg.select(\"avg_rating\").toPandas()\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(ratings['avg_rating'], bins=20, color='lightblue', edgecolor='black')\n",
    "plt.xlabel(\"Average Rating\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Average Ratings\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db8501",
   "metadata": {},
   "source": [
    "# Average Rating by Year (Line Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4faae3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte 'publishedDate' field and to Pandas\n",
    "df_books_with_year = df_avg_with_date.select(\"Title\", \"avg_rating\", \"publishedDate\").toPandas()\n",
    "\n",
    "# Extract year from the 'publishedDate'\n",
    "df_books_with_year['Year'] = pd.to_datetime(df_books_with_year['publishedDate'], errors='coerce').dt.year\n",
    "\n",
    "# Group by year and calculate average rating\n",
    "avg_ratings_by_year = df_books_with_year.groupby('Year')['avg_rating'].mean().reset_index()\n",
    "\n",
    "# Plot line plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x='Year', y='avg_rating', data=avg_ratings_by_year, marker='o', color='green')\n",
    "plt.title(\"Average Rating by Year\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Average Rating\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430406a",
   "metadata": {},
   "source": [
    "# Rating Distribution by Top 10 Author (Box Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b83478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average rating per author\n",
    "df_author_avg_rating = df_avg.groupBy(\"authors\").agg({\"avg_rating\": \"avg\"}).withColumnRenamed(\"avg(avg_rating)\", \"avg_author_rating\")\n",
    "\n",
    "# Convert the Spark DataFrame to Pandas for Seaborn plotting\n",
    "df_author_ratings = df_author_avg_rating.toPandas()\n",
    "\n",
    "# Sort authors by average rating\n",
    "df_author_ratings = df_author_ratings.sort_values(by=\"avg_author_rating\", ascending=False)\n",
    "\n",
    "# Limit to top 10 authors based on average rating\n",
    "top_authors = df_author_ratings.head(10)\n",
    "\n",
    "# Plot box plot for ratings by author\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"authors\", y=\"avg_author_rating\", data=top_authors)\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels and align them\n",
    "plt.title(\"Rating Distribution by Top 10 Authors\", fontsize=14)\n",
    "plt.xlabel(\"Authors\", fontsize=12)\n",
    "plt.ylabel(\"Average Rating\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a77422",
   "metadata": {},
   "source": [
    "# üìä Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b4901",
   "metadata": {},
   "source": [
    "### 1. Spark SQL Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd45b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Example: Compute average rating per genre\n",
    "df_avg = df_joined.groupBy(\"categories\").agg(avg(\"rating_score\").alias(\"avg_rating\"))\n",
    "df_avg.show()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"‚è± Spark query time: {end - start:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134ff57",
   "metadata": {},
   "source": [
    "### 2. MongoDB Aggregation Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04030e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "pipeline = [\n",
    "    { \"$group\": {\n",
    "        \"_id\": \"$categories\",\n",
    "        \"avg_rating\": { \"$avg\": \"$review/score\" }\n",
    "    }},\n",
    "    { \"$sort\": { \"avg_rating\": -1 } }\n",
    "]\n",
    "\n",
    "results = list(db[\"ratings\"].aggregate(pipeline))\n",
    "\n",
    "end = time.time()\n",
    "print(f\"‚è± MongoDB aggregation time: {end - start:.4f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
