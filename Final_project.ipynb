{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66fb3ee5",
   "metadata": {},
   "source": [
    "# üìò Final Project: Data Analysis using MongoDB and Apache Spark\n",
    "\n",
    "This project demonstrates how to work with a real-world dataset (Amazon Books Reviews Dataset) using MongoDB for storage and Apache Spark (PySpark) for processing. We explore schema design, querying, performance optimization, and visual insights.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f56ae",
   "metadata": {},
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df144e86",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Configure Pandas display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb67d72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Load CSV files\n",
    "books_df = pd.read_csv(\"books_data.csv\")\n",
    "ratings_df = pd.read_csv(\"Books_rating.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8bd1d8",
   "metadata": {},
   "source": [
    "## üìÇ Dataset Overview\n",
    "\n",
    "We use the **Amazon Books Reviews** dataset from Kaggle, which contains user-generated reviews for a wide variety of books available on Amazon. This real-world dataset includes valuable attributes such as:\n",
    "\n",
    "- **Title**: The name of the book.\n",
    "- **Author(s)**: The author(s) of the book.\n",
    "- **Categories**: Genre or subject of the book (e.g., Comics, Fiction, Education).\n",
    "- **Rating**: User rating scores, typically from 1 to 5.\n",
    "- **Review Text**: Actual written review provided by users.\n",
    "- **Review Date**: When the review was posted.\n",
    "- **ASIN**: Unique Amazon product identifier for each book.\n",
    "\n",
    "This dataset provides an excellent foundation for exploring data storage, processing, and analysis using MongoDB and Apache Spark due to its unstructured nature and scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0d1a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Basic exploration\n",
    "print(\"üìò Books Data Sample:\")\n",
    "print(books_df.head(), \"\\n\")\n",
    "\n",
    "print(\"üìù Ratings Data Sample:\")\n",
    "print(ratings_df.head(), \"\\n\")\n",
    "\n",
    "print(\"üìä Shapes:\")\n",
    "print(\"Books Data Shape:\", books_df.shape)\n",
    "print(\"Ratings Data Shape:\", ratings_df.shape, \"\\n\")\n",
    "\n",
    "print(\"üîç Missing Values in Books Data:\")\n",
    "print(books_df.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"üîç Missing Values in Ratings Data:\")\n",
    "print(ratings_df.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a02a937",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Optional Cleaning\n",
    "# Drop rows with missing essential review text\n",
    "ratings_df = ratings_df.dropna(subset=[\"review/text\"])\n",
    "\n",
    "\n",
    "# Fill missing summaries with a placeholder (safe version)\n",
    "ratings_df[\"review/summary\"] = ratings_df[\"review/summary\"].fillna(\"No summary provided\")\n",
    "\n",
    "\n",
    "# You can apply similar cleaning to books_df if needed\n",
    "# books_df = books_df.dropna()  # example"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
